{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca05ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import atleast_2d as twod\n",
    "import pandas as pd\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f8bd932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "DATA_DIR = \"facial_expressions/data\"\n",
    "IMAGE_DIR = \"facial_expressions/images\"\n",
    "data = pd.read_csv(f'{DATA_DIR}/legend.csv')\n",
    "data['emotion'] = data['emotion'].str.lower()\n",
    "# data['image'] = np.array([plt.imread(IMAGE_DIR + '/' + image) for image in data['image']], dtype=object)\n",
    "# data['image'] = np.array([color.rgb2gray(image) if len(image.shape)==3 else image for image in data['image']], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "233ba0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping training datasets\n",
    "X = []\n",
    "# Ran into too many files open error: https://stackoverflow.com/questions/29234413/too-many-open-files-error-when-opening-and-loading-images-in-pillow\n",
    "# find the minimum width and height and I can resize all images to that shape\n",
    "min_width = 1000\n",
    "min_height = 1000\n",
    "temp_image = None\n",
    "for image in data['image']:\n",
    "    temp = Image.open(IMAGE_DIR + '/' + image)\n",
    "    keep = temp.copy().convert('L')\n",
    "    if keep.size[0] == 18:\n",
    "        temp_image = keep\n",
    "    min_width = min(min_width, keep.size[0])\n",
    "    min_height = min(min_height, keep.size[1])\n",
    "    X.append(keep)\n",
    "    temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db6e32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps from Wikipedia: https://en.wikipedia.org/wiki/Eigenface\n",
    "# All images should be resampled to a common pixel resolution\n",
    "X = [image.resize((min_width, min_height)) for image in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7bb6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image will be treated as a vector, concatenate all rows in an image to a single column\n",
    "# Store all images in the training set into one matrix, T\n",
    "# X = np.array([])\n",
    "# Y = np.array(data['emotion'])\n",
    "# classes = np.array(set(Y))\n",
    "# # Spliting data in to training and validation sets\n",
    "# split_factor = 0.8\n",
    "# stop = int(split_factor * len(X))\n",
    "# Xtr,Xva = X[:stop],X[stop:]\n",
    "# Ytr,Yva = Y[:stop],Y[stop:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55d2361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Calculate average image and subtract that from each original image/column in T\n",
    "# Calculate the eigenvectors and eigenvalues of the covariance matrix of the new matrix\n",
    "# Sort eigenvalues in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "736db726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# Use the train model to predict emotion on validation data set\n",
    "# Calculate performance\n",
    "print(min_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9161b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAGFCAYAAAChRwUXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAN4ElEQVR4nO3dTW/V5dbA4bu0pS9AS2mrpRQqECS+YFRiMChxZoxh5vkEjkyc+CGcOnDs1IkzExNNjBOjAwdgfEmIaNCAQCiQCoUW6N7tPh/gOdqdtcLDOjnXNd6Ltdvu/vgPyGKg1+v1GkBR2x71GwD4JyIFlCZSQGkiBZQmUkBpIgWUJlJAaSIFlDbU7wsvX778MN/HPxoa6vtt/h8jIyOp3X/99Vd49tNPP03t/vzzz8OzFy5cSO3O/BvfwcHB1O6MhYWF8Oxbb72V2n369Onw7Pbt21O7O51OeDb777kz84cPH97yNZ6kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihtoN//d+/q1avhJRsbG+HZ1lobHx8Pz/7444+p3e+//3549qeffkrtzpw8yZ7+yJzH2bYt/nff+vp6eLa11h48eBCezXzNrbX26quvhmffe++91O4nnngiPJv5nrWWO9Vy6NChLV/jSQooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKK3ve1I3b9582O/lb507dy48++6776Z2X79+PTybuYPVWu5OT2a2tfw9qqjs+87cLsveVep2u+HZffv2pXZ/8MEH4dknn3wytbvT6YRnDx48uOVrPEkBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUFrfp1pu374dXrK8vByeba21d955Jzx79uzZ1O6jR4+GZ48cOZLanTn1Mjg4mNp9//798GzmszI5ORmezc5funQptfvixYvh2d9//z21+8SJE+HZDz/8MLV7aGgoPLu4uLjlazxJAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGl9X0IZmRkJLzks88+C8+21tp3330Xnl1YWEjtPn78eHh2bm4utTtzp+e/1djY2CObf+6551K7M3e0vvjii9TuzO/It99+m9r9+uuvp+a34kkKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNL6vgXS7XbDS7755pvwbGutbdsWb+nevXtTu6empsKzme9Za62tr6+HZ3u9Xmr3wMBAaj4q+z3LzI+OjqZ2Z07rnDx5MrX7woUL4dkzZ86kdjvVAvxPEymgNJECShMpoDSRAkoTKaA0kQJKEymgNJECShMpoDSRAkoTKaA0kQJKEymgtL5vS9y6dSu85PLly+HZ1lobHh4Oz46Pj6d2j4yMhGf/V8+OZE7MZM7ytJY7MZP5nGXns1/33NxceHZpaSm1u9PppOa34kkKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECijt/+WeVGa2tdamp6fDswcPHkzt/uGHH8Kz586dS+3O3LI6cOBAavfzzz8fnp2YmAjPrqyshGdba+3XX38Nz165ciW1O3PD6+TJk6ndmd+RP//8M7U7+zPbiicpoDSRAkoTKaA0kQJKEymgNJECShMpoDSRAkoTKaA0kQJKEymgNJECShMpoDSRAkrr+1TL0tLSw3wf/+jUqVPh2cy5k9Zau3HjRng2cz6jtda63W549v79+6ndly9fDs9mzuP0er3wbNbm5mZqfnl5OTx75syZ1O79+/eHZ1dXV1O7h4eHU/Nb8SQFlCZSQGkiBZQmUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWUJlJAaSIFlCZSQGkiBZTW9z2pTz75JLxk79694dnWWnvqqafCs9lbOZn3fufOndTuq1evhmcnJiZSu2dmZsKzBw4cCM/eu3cvPNtaa99//314NnNDq7XWXnjhhfDs6Ohoanfmd2RlZSW1+48//gjPHj16dMvXeJICShMpoDSRAkoTKaA0kQJKEymgNJECShMpoDSRAkoTKaA0kQJKEymgNJECShMpoLS+T7VkTn8sLi6GZ1trbXx8PDw7Ozub2j05ORmezZ7+mJubC88uLCykds/Pz4dnM9+z6enp8Gxrrb344ovh2ex5m2PHjoVnd+zYkdr9+OOPh2efffbZ1O6ff/45PPvGG29s+RpPUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWUJlJAaX3fk1pbWwsv6fV64dnWWhsbGwvPPsp7UtkbQZnv2+DgYGr3tm3xv792794dnu10OuHZ1lo7efJkePbpp59O7c58TjOfs9ZaW11dDc9ubm6mdu/duzc1vxVPUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWU1veplvn5+fCS7PmNbrcbnr1z505q98jISHg2c+6ktdaWl5fDs6Ojo6nd4+Pj4dm7d++GZ3fu3BmebS33WZmYmEjtzpyoyX7dmd+xBw8epHZnTxJtxZMUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaX1fapleno6vOT69evh2dZaW1tbC89ubGykdg8MDIRnr1y5ktq9tLQUnr127Vpqd+b8xuLiYmp3RuZEzf79+1O7M6d5sueMMp/zQ4cOpXbPzMyk5rfiSQooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKK3ve1Ivv/xyeMnZs2fDs621dvv27fDs+vp6andmfnV1NbV7fn4+PLtz587U7rt374Znl5eXw7PZW1Szs7Ph2eztsczdtN27d6d2Z+5RDQ8Pp3ZPTU2l5rfiSQooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0gZ6vV6vnxfev38/vCQz21prH3/8cXj21q1bqd2Z8x1ra2up3Tt27AjPbm5upnZ3u93w7Pj4eHh2z5494dnWWpucnAzPZk+1ZL7nY2Njqd0ZzzzzTGp+YmIiPLuwsLDlazxJAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGlDfX7wsx9oe3bt4dnW2tteno6PHvjxo3U7m3b4h3P3tFaWloKz54/fz61++bNm+HZ0dHR8Oz8/Hx4trXWXnrppfDsvn37Urt37doVns3eHltcXAzPzszMpHavr6+n5rfiSQooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0vo+1ZIxODiYms+c/siekcjszn7dV65cCc9euHAhtXtiYiI8e/fu3fDsl19+GZ5tLXce51//+ldq9+bmZng2+1nJnGrZ2NhI7X7YPEkBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUFrfp1q2bYv3bGRkJDzbWmvDw8Ph2QcPHqR2Z05oDA3lLuEcO3YsPDs+Pp7anfl5Z35eMzMz4dnWWnvllVfCs9mf18rKSnh2YWEhtXvXrl3h2U6nk9qd+az09ec/1D8dIEmkgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECiit7wM69+7dCy/5+uuvw7OttXb27NnwbPZWztraWng2e0er2+2GZ0+cOJHaffPmzfBs5rNy/Pjx8GxrubtKAwMDqd2P8rOyffv28Ozm5mZqd+Zz2g9PUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWUJlJAaSIFlCZSQGkiBZQmUkBpIgWUNtDr9Xr9vPD06dPhJRcvXgzPttbaqVOnwrNDQ31fo/mPVlZWwrN79uxJ7c6c/si879Zam5+fD88ODw+HZ8fGxsKzreW+59mTI+vr6+HZzM+6tdZ2794dnn3zzTdTu2dnZ8OzU1NTW77GkxRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUFrf96QOHz78sN/L33rttdfCs3Nzc6ndly5dCs9ubm6mdo+OjoZn79y5k9qduUfVz42gv3Po0KHwbGut7dy5Mzzb6XRSuzOftV9++SW1+6uvvgrPHjlyJLU7c2vu7bff3vI1nqSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKE2kgNJECihNpIDSRAooTaSA0kQKKG2o3xd2u93wkuzJkvPnz4dn9+/fn9o9MTERnr1x40Zq9/Lycnh2aKjvH+1/NDk5+Uh2r66uhmdba21wcDA8+9hjj6V2Zz4rAwMDqd2Zr/vixYup3R999FF41qkW4L+eSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQmkgBpYkUUJpIAaWJFFCaSAGliRRQWt+HfzqdTnhJ5tZNa61dunQpPJu5RdVaa7Ozs+HZ7I2gsbGx8Oy1a9dSu2/duhWePXLkSHh2amoqPNtaa6Ojo+HZ7M9rY2MjPPvbb7+ldmd+Px/lLat+eJICShMpoDSRAkoTKaA0kQJKEymgNJECShMpoDSRAkoTKaA0kQJKEymgNJECShMpoLSBXq/Xe9RvAuDveJICShMpoDSRAkoTKaA0kQJKEymgNJECShMpoDSRAkr7N/5ncdepBsnvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ea236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
